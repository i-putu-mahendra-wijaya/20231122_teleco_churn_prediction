{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part03 Algorithm Implementation, Model Training, and Performance Measurement"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ca93b2f45fc31e1"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import modeules\n",
    "\n",
    "from typing import List, Dict, Union\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from src.classes.NpData import NpData\n",
    "from src.commons.Utils import impute_scale_and_convert_to_numpy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:17.129095Z",
     "start_time": "2023-11-24T14:17:15.177955Z"
    }
   },
   "id": "46519d9219b9a9a7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# read training dataset\n",
    "ohe_train: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=\"../../dataset/01_interim/ohe_train.csv\"\n",
    ")\n",
    "\n",
    "churn_train: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=\"../../dataset/01_interim/churn_train.csv\"\n",
    ")\n",
    "\n",
    "ohe_val: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=\"../../dataset/01_interim/ohe_val.csv\"\n",
    ")\n",
    "\n",
    "churn_val: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=\"../../dataset/01_interim/churn_val.csv\"\n",
    ")\n",
    "\n",
    "ohe_test: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=\"../../dataset/01_interim/ohe_test.csv\"\n",
    ")\n",
    "\n",
    "churn_test: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=\"../../dataset/01_interim/churn_test.csv\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:17.191170Z",
     "start_time": "2023-11-24T14:17:17.134903Z"
    }
   },
   "id": "5deedfbeed32e3b0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open(file=\"../../config.yaml\", mode=\"r\") as file_stream: \n",
    "    stream_loader = yaml.load(\n",
    "        stream=file_stream,\n",
    "        Loader=yaml.SafeLoader\n",
    "    )\n",
    "    mean_total_charges: float = stream_loader[\"MEAN_TOTAL_CHARGES\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:17.199356Z",
     "start_time": "2023-11-24T14:17:17.194750Z"
    }
   },
   "id": "d9bcf80b2fe13553"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "scaler_folder: str = f\"../../models/scaler\"\n",
    "\n",
    "feature_train_np: np.ndarray\n",
    "churn_train_np: np.ndarray\n",
    "\n",
    "feature_val_np: np.ndarray\n",
    "churn_val_np: np.ndarray\n",
    "\n",
    "feature_test_np: np.ndarray\n",
    "churn_test_np: np.ndarray\n",
    "\n",
    "feature_train_np, churn_train_np = impute_scale_and_convert_to_numpy(\n",
    "    ohe_df=ohe_train,\n",
    "    columns_with_nulls=[\"TotalCharges\"],\n",
    "    impute_val=[mean_total_charges],\n",
    "    scaler_folder=scaler_folder,\n",
    "    churn_df=churn_train\n",
    ")\n",
    "\n",
    "feature_val_np, churn_val_np = impute_scale_and_convert_to_numpy(\n",
    "    ohe_df=ohe_val,\n",
    "    columns_with_nulls=[\"TotalCharges\"],\n",
    "    impute_val=[mean_total_charges],\n",
    "    scaler_folder=scaler_folder,\n",
    "    churn_df=churn_val    \n",
    ")\n",
    "\n",
    "feature_test_np, churn_test_np = impute_scale_and_convert_to_numpy(\n",
    "    ohe_df=ohe_test,\n",
    "    columns_with_nulls=[\"TotalCharges\"],\n",
    "    impute_val=[mean_total_charges],\n",
    "    scaler_folder=scaler_folder,\n",
    "    churn_df=churn_test    \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:17.356987Z",
     "start_time": "2023-11-24T14:17:17.204616Z"
    }
   },
   "id": "461f90439e7d9f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok, so we have : \n",
    " (1) imported all necessary modules\n",
    " (2) load train, validation, and test dataset\n",
    " (3) impute, scale, and convert the dataset to numpy\n",
    "\n",
    "Now, we will subject all feature_** to PCA, so that we can get denser representation instead of a sparse matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95f96fee7abc9856"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load trained PCA\n",
    "pca: PCA = joblib.load(\n",
    "    filename=\"../../models/feature_pca.pkl\",\n",
    ")\n",
    "\n",
    "feature_train_pca: np.ndarray = pca.transform(feature_train_np)\n",
    "feature_val_pca: np.ndarray = pca.transform(feature_val_np)\n",
    "feature_test_pca: np.ndarray = pca.transform(feature_test_np)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:17.370877Z",
     "start_time": "2023-11-24T14:17:17.363255Z"
    }
   },
   "id": "2a065761385c1ef8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# initiate candidate models\n",
    "\n",
    "# LogisticRegression is famous for being the simplest model for binary classification task such as churn prediction. \n",
    "# We can use LogisticRegression model as the base whose performance against which to compare other models\n",
    "lr_classifier: LogisticRegression = LogisticRegression()\n",
    "\n",
    "# RandomForestClassifier is a famous ensemble algorithm used for multi-class classification. It can handle binary classification as well\n",
    "# The algorithm is an ensemble algorithm based on tree simple learners\n",
    "# The algorithm make classification by taking a \"voting\" from all the trees trained\n",
    "rf_classifier: RandomForestClassifier = RandomForestClassifier()\n",
    "\n",
    "# GradientBoostingClassifier is another ensemble algorithm used for multi-class classification. \n",
    "# This algorithm too are based on tree simple learners\n",
    "# In the GradientBoosting algorithm, however, the tree are arranged in sequence, whereby each sequence down the line try to rectify the error made upstream simple learner(s)\n",
    "gb_classifier: GradientBoostingClassifier = GradientBoostingClassifier()\n",
    "\n",
    "# Finally, SupportVectorMachine (SVM) classifier (SVC) is another algorithm that can be used for classification task\n",
    "# This algorithm aims to \"project\" the data points to ever higher dimensions until a hyperplane can be found that separate the data points into classes\n",
    "sv_classifier: SVC = SVC()\n",
    "\n",
    "\n",
    "# We start all models with default hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:17.381527Z",
     "start_time": "2023-11-24T14:17:17.377968Z"
    }
   },
   "id": "3f39a627d7f6c07f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Combining all these candidate models into Dictionary \n",
    "class ModelCandidate(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            classification_model: Union[LogisticRegression, RandomForestClassifier, GradientBoostingClassifier, SVC],\n",
    "            n_class: int\n",
    "    ) -> None:\n",
    "        self.classification_model: Union[LogisticRegression, RandomForestClassifier, GradientBoostingClassifier, SVC] = classification_model\n",
    "        self.confusion_matrix: np.ndarray = np.empty(shape=(n_class, n_class))\n",
    "        self.accuracy_score: float = 0.0\n",
    "        self.f1_score: float = 0.0\n",
    "        self.training_time: float = 0.0 \n",
    "    \n",
    "    \n",
    "    def save_trained_model(\n",
    "            self, \n",
    "            trained_model: Union[LogisticRegression, RandomForestClassifier, GradientBoostingClassifier, SVC]\n",
    "    ) -> None:\n",
    "        self.classification_model = trained_model\n",
    "    \n",
    "    \n",
    "    def log_training_time(\n",
    "            self, \n",
    "            training_time: float\n",
    "    ) -> None:\n",
    "        self.training_time = training_time\n",
    "    \n",
    "    def calculate_accuracy(\n",
    "            self, \n",
    "            y_true: np.ndarray,\n",
    "            y_pred: np.ndarray\n",
    "    ) -> None:\n",
    "        self.accuracy_score = accuracy_score(\n",
    "            y_true=y_true,\n",
    "            y_pred=y_pred\n",
    "        )\n",
    "    \n",
    "    def calculate_confusion_matrix(\n",
    "            self, \n",
    "            y_true: np.ndarray,\n",
    "            y_pred: np.ndarray\n",
    "    ) -> None:\n",
    "        self.confusion_matrix = confusion_matrix(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred\n",
    "        )\n",
    "    \n",
    "    def calculate_f1_score(\n",
    "            self, \n",
    "            y_true: np.ndarray,\n",
    "            y_pred: np.ndarray\n",
    "    ) -> None:\n",
    "        self.f1_score = f1_score(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "classifier_candidates: Dict[str, ModelCandidate] = {\n",
    "    \"lr_classifier\": ModelCandidate(classification_model=lr_classifier, n_class=len(np.unique(churn_train_np))),\n",
    "    \"rf_classifier\": ModelCandidate(classification_model=rf_classifier, n_class=len(np.unique(churn_train_np))),\n",
    "    \"gb_classifier\": ModelCandidate(classification_model=gb_classifier, n_class=len(np.unique(churn_train_np))),\n",
    "    \"sv_classifier\": ModelCandidate(classification_model=sv_classifier, n_class=len(np.unique(churn_train_np)))\n",
    "}\n",
    "\n",
    "for _, each_candidate in classifier_candidates.items():\n",
    "    _tic: float = time.time()\n",
    "    \n",
    "    _classifier_model = each_candidate.classification_model\n",
    "    _classifier_model.fit(\n",
    "        X=feature_train_pca,\n",
    "        y=churn_train_np.ravel()\n",
    "    )\n",
    "    \n",
    "    each_candidate.save_trained_model(trained_model=_classifier_model)\n",
    "    \n",
    "    _toc: float = time.time()\n",
    "    training_time: float = _toc - _tic\n",
    "    each_candidate.log_training_time(training_time=training_time)\n",
    "    \n",
    "    y_pred: np.ndarray = _classifier_model.predict(X=feature_val_pca)\n",
    "    \n",
    "    each_candidate.calculate_accuracy(\n",
    "        y_true=churn_val_np.ravel(),\n",
    "        y_pred=y_pred\n",
    "    )\n",
    "    \n",
    "    each_candidate.calculate_f1_score(\n",
    "        y_true=churn_val_np.ravel(),\n",
    "        y_pred=y_pred        \n",
    "    )\n",
    "    \n",
    "    each_candidate.calculate_confusion_matrix(\n",
    "        y_true=churn_val_np.ravel(),\n",
    "        y_pred=y_pred        \n",
    "    )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:20.286315Z",
     "start_time": "2023-11-24T14:17:17.395409Z"
    }
   },
   "id": "c38545d5836603b8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_classifier training time is 0.008517742156982422 seconds\n",
      "lr_classifier accuracy is 0.7420078519349411\n",
      "lr_classifier f1_score is 0.6904441453566622\n",
      "------------------------------\n",
      "rf_classifier training time is 0.8806240558624268 seconds\n",
      "rf_classifier accuracy is 0.807627593942793\n",
      "rf_classifier f1_score is 0.788140827671402\n",
      "------------------------------\n",
      "gb_classifier training time is 0.8179631233215332 seconds\n",
      "gb_classifier accuracy is 0.7453729669097028\n",
      "gb_classifier f1_score is 0.6997354497354497\n",
      "------------------------------\n",
      "sv_classifier training time is 0.7209358215332031 seconds\n",
      "sv_classifier accuracy is 0.7352776219854178\n",
      "sv_classifier f1_score is 0.6890645586297759\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for each_key, each_candidate in classifier_candidates.items():\n",
    "    print(f\"{each_key} training time is {each_candidate.training_time} seconds\")\n",
    "    print(f\"{each_key} accuracy is {each_candidate.accuracy_score}\")\n",
    "    print(f\"{each_key} f1_score is {each_candidate.f1_score}\")\n",
    "    print(\"---\"*10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:20.293977Z",
     "start_time": "2023-11-24T14:17:20.286694Z"
    }
   },
   "id": "3c721051e54e01e2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T14:17:20.300619Z",
     "start_time": "2023-11-24T14:17:20.294739Z"
    }
   },
   "id": "7ebd153d450f01f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
